#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ LLM å¯¹å·²æŠ“å–çš„è®ºæ–‡è¿›è¡Œé‡æ–°åˆ†ç±»

è¿™ä¸ªè„šæœ¬è¯»å–ä¹‹å‰æŠ“å–çš„è®ºæ–‡æ•°æ®ï¼Œä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½åˆ†ç±»ï¼Œ
å¹¶å°†ç»“æœä¸è§„åˆ™åˆ†ç±»è¿›è¡Œå¯¹æ¯”ã€‚
"""

import pandas as pd
import sys
import os

from icl_taxonomy import RuleClassifier
from icl_classifier import LLMClassifier, HybridClassifier
from config_loader import load_config

# ä»é…ç½®æ–‡ä»¶åŠ è½½ API ä¿¡æ¯
config = load_config()
API_CONFIG = {
    "api_base": config.api_base,
    "api_key": config.api_key,
    "model": config.model
}

# æ£€æŸ¥APIå¯†é’¥æ˜¯å¦é…ç½®
if not API_CONFIG["api_key"]:
    print("\nâŒ é”™è¯¯: æœªé…ç½® API å¯†é’¥")
    print("è¯·ç¼–è¾‘ config.json æ–‡ä»¶ï¼Œåœ¨ 'api.api_key' å­—æ®µä¸­å¡«å…¥æ‚¨çš„ API å¯†é’¥")
    sys.exit(1)


def main():
    # è¯»å–å·²æœ‰æ•°æ®
    csv_path = "out/icl_papers_filtered.csv"
    if not os.path.exists(csv_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {csv_path}")
        print("è¯·å…ˆè¿è¡Œä¸»ç¨‹åºæŠ“å–æ•°æ®ï¼š")
        print("  python3 openreview_icl_crawl_and_plot.py")
        return

    print("=" * 70)
    print("LLM è®ºæ–‡é‡åˆ†ç±»å·¥å…·")
    print("=" * 70)
    print()

    # è¯»å–æ•°æ®
    df = pd.read_csv(csv_path, encoding="utf-8-sig")
    print(f"âœ“ è¯»å–åˆ° {len(df)} ç¯‡è®ºæ–‡")
    print()

    # è¯¢é—®ç”¨æˆ·è¦å¤„ç†å¤šå°‘ç¯‡
    print("é€‰é¡¹:")
    print("  1. æµ‹è¯•æ¨¡å¼ (å‰5ç¯‡)")
    print("  2. å°è§„æ¨¡ (å‰20ç¯‡)")
    print("  3. ä¸­ç­‰è§„æ¨¡ (å‰50ç¯‡)")
    print("  4. å…¨éƒ¨è®ºæ–‡ ({}ç¯‡)".format(len(df)))
    print()

    choice = input("è¯·é€‰æ‹© [1-4ï¼Œé»˜è®¤1]: ").strip() or "1"

    if choice == "1":
        num_papers = 5
    elif choice == "2":
        num_papers = 20
    elif choice == "3":
        num_papers = 50
    else:
        num_papers = len(df)

    df_sample = df.head(num_papers).copy()
    print(f"\nå¤„ç† {len(df_sample)} ç¯‡è®ºæ–‡...")
    print()

    # å‡†å¤‡æ•°æ®
    papers = []
    for idx, row in df_sample.iterrows():
        papers.append({
            'id': f"paper_{idx}",
            'title': row['title'],
            'abstract': row['abstract'],
            'original_category': row['category']  # åŸå§‹è§„åˆ™åˆ†ç±»ç»“æœ
        })

    # åˆå§‹åŒ–åˆ†ç±»å™¨
    print("[1] åˆå§‹åŒ–åˆ†ç±»å™¨...")
    rule_classifier = RuleClassifier()
    llm_classifier = LLMClassifier(
        api_base=API_CONFIG['api_base'],
        api_key=API_CONFIG['api_key'],
        model=API_CONFIG['model'],
        cache_file="reclassify_cache.json",
        max_rpm=20  # é™åˆ¶é€Ÿç‡
    )

    hybrid_classifier = HybridClassifier(
        llm_classifier=llm_classifier,
        rule_classifier=rule_classifier,
        confidence_threshold=0.6
    )
    print("    âœ“ åˆå§‹åŒ–å®Œæˆ")
    print()

    # æ‰§è¡Œåˆ†ç±»
    print(f"[2] ä½¿ç”¨ LLM åˆ†ç±» (æ¨¡å‹: {API_CONFIG['model']})...")
    print("    è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    print()

    results = hybrid_classifier.classify_papers(
        papers=[{k: v for k, v in p.items() if k != 'original_category'} for p in papers],
        batch_size=5,  # å°æ‰¹é‡å¤„ç†
        checkpoint_file="reclassify_checkpoint.json",
        verbose=True
    )

    # å¯¹æ¯”ç»“æœ
    print("\n[3] å¯¹æ¯”åˆ†ç±»ç»“æœ:")
    print("=" * 70)

    changes = 0
    llm_used = 0

    for paper, result in zip(papers, results):
        original = paper['original_category']
        new = result['category_label']
        method = result.get('method', 'rule')

        if method == 'llm':
            llm_used += 1

        if original != new:
            changes += 1
            print(f"\nğŸ“„ {paper['title'][:60]}...")
            print(f"   åŸåˆ†ç±»: {original}")
            print(f"   æ–°åˆ†ç±»: {new}")
            print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2f}")
            print(f"   æ–¹æ³•: {method}")
            if 'reasoning' in result:
                print(f"   ç†ç”±: {result['reasoning'][:100]}...")

    # ç»Ÿè®¡
    print("\n" + "=" * 70)
    print("ç»Ÿè®¡:")
    print(f"  æ€»è®¡å¤„ç†: {len(papers)} ç¯‡")
    print(f"  LLM åˆ†ç±»: {llm_used} ç¯‡")
    print(f"  è§„åˆ™åˆ†ç±»: {len(papers) - llm_used} ç¯‡")
    print(f"  åˆ†ç±»æ”¹å˜: {changes} ç¯‡ ({changes/len(papers)*100:.1f}%)")

    # ä¿å­˜ç»“æœ
    output_df = pd.DataFrame(results)
    output_path = "out/icl_papers_llm_reclassified.csv"
    output_df.to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

    # åˆ†ç±»åˆ†å¸ƒ
    print("\næ–°åˆ†ç±»åˆ†å¸ƒ:")
    print(output_df['category_label'].value_counts().to_string())

    print("\n" + "=" * 70)
    print("å®Œæˆï¼")
    print()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
